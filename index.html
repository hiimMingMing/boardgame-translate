<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Image to Text to Speech</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tesseract.js/4.0.2/tesseract.min.js"></script>
    <style>
      body {
        font-family: Arial, sans-serif;
        text-align: center;
        padding: 20px;
      }
      video,
      canvas,
      img {
        width: 100%;
        max-width: 400px;
        margin: 10px 0;
      }
      button {
        padding: 10px;
        margin: 5px;
        font-size: 16px;
      }
    </style>
  </head>
  <body>
    <h2>Image to Text to Speech</h2>
    <video id="camera" autoplay playsinline></video>
    <canvas id="canvas" style="display: none"></canvas>
    <button onclick="captureImage()">Capture</button>
    <img id="capturedImage" style="display: none" />
    <p><strong>Extracted Text:</strong></p>
    <p id="extractedText"></p>
    <p><strong>Translated Text:</strong></p>
    <p id="translatedText"></p>
    <button onclick="readText()">Read Aloud</button>

    <script>
      // Start camera
      const video = document.getElementById("camera");
      navigator.mediaDevices
        .getUserMedia({ video: { facingMode: "environment" } })
        .then((stream) => {
          video.srcObject = stream;
        });

      function captureImage() {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const img = document.getElementById("capturedImage");
        img.src = canvas.toDataURL("image/png");
        img.style.display = "block";

        extractText(img.src);
      }

      function extractText(imageSrc) {
        Tesseract.recognize(imageSrc, "eng").then(({ data: { text } }) => {
          document.getElementById("extractedText").innerText = text;
          translateText(text);
        });
      }

      async function translateText(text) {
        const apiKey = process.env.OPENAI_API_KEY;
        const response = await fetch(
          "https://api.openai.com/v1/chat/completions",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${apiKey}`,
            },
            body: JSON.stringify({
              model: "gpt-4",
              messages: [
                { role: "system", content: "Translate this to Vietnamese:" },
                { role: "user", content: text },
              ],
            }),
          }
        );

        const data = await response.json();
        const translatedText = data.choices[0].message.content;
        document.getElementById("translatedText").innerText = translatedText;
      }

      function readText() {
        const text = document.getElementById("translatedText").innerText;
        const speech = new SpeechSynthesisUtterance(text);
        speech.lang = "vi-VN"; // Vietnamese voice
        window.speechSynthesis.speak(speech);
      }
    </script>
  </body>
</html>
